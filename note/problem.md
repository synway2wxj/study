# 定时任务集群环境部署
如何限定只有一台机器在执行定时任务
某台服务宕机以后如何进行故障转移
如何确定正在执行的是哪一台服务
* 利用mysql的排他锁
* quartz集群需要数据库的支持（JobStore TX或者JobStoreCMT），从本质上来说，是使集群上的每一个节点通过共享同一个数据库来工作的；在\docs\dbTables下选择合适你数据库的SQL执行文件，创建quartz集群需要的表
quartz
quartz-jobs 
https://www.liangzl.com/get-article-detail-718.html
* 固定执行定时任务的机器
在数据库建立多张表，从定时任务表中获取定时方法
借助Redis的过期机制和分布式锁
Quartz的集群应用方式
Springboot 集成 quartz为什么非要集成呢, 因为quartz支持集群定时任务, 现在还用不到, 防止以后用到

# java内存
* 你的Java程序中所分配的每一个对象都需要存储在内存里；堆的大小可以通过JVM选项-Xms和-Xmx来进行调整
* Eden区 —— 新对象或者生命周期很短的对象会存储在这个区域中，这个区的大小可以通过-XX:NewSize和-XX:MaxNewSize参数来调整。新生代GC（垃圾回收器）会清理这一区域
* Survivor区 —— 那些历经了Eden区的垃圾回收仍能存活下来的依旧存在引用的对象会待在这个区域。这个区的大小可以由JVM参数-XX:SurvivorRatio来进行调节
* 老年代 —— 那些在历经了Eden区和Survivor区的多次GC后仍然存活下来的对象
* 方法区（非堆区域）
* 持久代 —— 这个区域会 存储包括类定义，结构，字段，方法（数据及代码）以及常量在内的类相关数据。它可以通过-XX:PermSize及 -XX:MaxPermSize来进行调节
* JVM栈 它会存储局部变量以及方法调用的中间结果及返回值 Java中的每个线程都有自己专属的栈，这个栈是别的线程无法访问的 可以通过JVM选项-Xss来进行调整
* 本地栈 用于本地方法 按线程分配
* PC寄存器 特定线程的程序计数器
* 元空间 它是本地堆内存中的一部分 它可以通过-XX:MetaspaceSize和-XX:MaxMetaspaceSize来进行调整 和持久代相关的JVM参数-XX:PermSize及-XX:MaxPermSize将会被忽略掉，并且在启动的时候给出警告信息 充分利用了Java语言规范中的好处：类及相关的元数据的生命周期与类加载器的一致
* 使用-XX:MaxMetaspaceSize参数可以设置元空间的最大值，默认是没有上限的，也就是说你的系统内存上限是多少它就是多少。
使用-XX:MetaspaceSize选项指定的是元空间的初始大小，如果没有指定的话，元空间会根据应用程序运行时的需要动态地调整大小
*  一旦类元数据的使用量达到了“MaxMetaspaceSize”指定的值，对于无用的类和类加载器，垃圾收集此时会触发。为了控制这种垃圾收集的频率和延迟，合适的监控和调整Metaspace非常有必要。过于频繁的Metaspace垃圾收集是类和类加载器发生内存泄露的征兆，同时也说明你的应用程序内存大小不合适，需要调整
* 消息事务+最终一致性（基于消息中间件的两阶段提交，本质上是对消息中间件的一种特殊利用，它是将本地事务和发消息放在了一个分布式事务里，保证要么本地操作成功成功并且对外发消息成功，要么两者都失败，开源的RocketMQ就支持这一特性；基于消息中间件的两阶段提交往往用在高并发场景下，将一个分布式事务拆成一个消息事务（A系统的本地操作+发消息）+B系统的本地操作，其中B系统的操作由消息驱动，只要消息事务成功，那么A操作一定成功，消息也一定发出来了，这时候B会收到消息去执行本地操作，如果本地操作失败，消息会重投，直到B操作成功）
* TCC编程模式（TCC提供了一个编程框架，将整个业务逻辑分为三块：Try、Confirm和Cancel三个操作）
* git clone https://github.com/davenkin/jta-atomikos-hibernate-activemq.git
* Java通过JTA完成分布式事务，JTA本身只是一种规范，不同的应用服务器都包含有自己的实现（比如JbossJTA），同时还存在独立于应用服务器的单独JTA实现，比如本篇中要讲到的Atomiko
* 将使用Hibernate来完成数据持久化，然后使用Spring提供的JmsTemplate将Order转成xml后以TextMessage的形式发送到物流部门的ORDER.QUEUE

# 高并发
* 高并发业务除了需要有支撑高并发的服务器架构，还需要根据业务需求和架构体系，设计出合理的开发方案（数据缓存到Redis、缓存刷新接口、未来时间缓存提前更新、缓存版本Key存储到列表 ：列表可以用来筛选出当前时间可以使用的最新版本号）
* 商品分页数据生成JSON数据文件存储到cdn中（接口性能、接口的稳定、容错机制、服务端压力：竟可能减少服务端压力，可以与客户端交互配合、服务降级：资源高压力的情况下进行降级）
* 在开发高并发系统时有三把利器用来保护系统：缓存、降级和限流
* TPS/QPS
* 如果你使用过Tomcat，其Connector 其中一种配置有如下几个参数：
acceptCount：如果Tomcat的线程都忙于响应，新来的连接会进入队列排队，如果超出排队大小，则拒绝连接；
maxConnections： 瞬时最大连接数，超出的会排队等待；
maxThreads：Tomcat能启动用来处理请求的最大线程数，如果请求处理量一直远远大于最大线程数则可能会僵死
* 限流某个接口的总并发/请求数（可以使用Java中的AtomicLong进行限流、使用Guava的Cache来存储计数器，过期时间设置为2秒（保证1秒内的计数器是有的），然后我们获取当前时间戳然后取秒数来作为KEY进行计数统计和限流、Guava框架提供了令牌桶算法实现，可直接拿来使用）
* 一个静态的html等内容，一个秒杀的web后天接口
* qps 每秒查询/处理数；将流量拒绝，再重启
* 在程序入口处，一个账号只允许接受一个请求，其它请求过滤
* 检测置指定机器ip请求频率，发现某个ip请求频率很高，弹出一个验证码或者直接禁止它的请求
* 通过数据挖掘提前清理掉一些账号；设置参与门槛/账号等级
* 数据挖掘，将经常抢票、退票，节假日异常活跃，将它们分析出来，再做进一步处理
* 深度开源
* 减少数据库访问次数，文件和数据库分离，大数据分布式存储，服务器的集群负载均衡，页面缓存的使用，nosql内存数据库代替关系型数据库
* 图片、视频、其他下载文件，它们的下载通常是占用网络带宽的罪恶魁首，这些资源一定要独立放在带宽好的文件服务器上，能提供http协议访问地址使用，不至于在下载文件时影响web服务器的cpu运算
* web api 接口上传文件结果一定要返回特定服务器完整的http文件下载地址，这个地址要存入数据库
* redis官方推荐使用的Redisson就提供了分布式锁和相关服务
* 生成的ID通常要满足分片的一些要求：不能有单点故障  以时间为序，或者ID里包含时间。这样一是可以少一个索引，二是冷热数据容易分离 可以控制ShardingId 不要太长，最好64bit
* twitter：全局唯一ID生成服务：Snowflake
* 基于redis的分布式ID生成器

# 分布式
* 垂直拆分就是把一个数据库中不同业务单元的数据分到不同的数据库里面
* 水平拆分是根据一定的规则把同一业务单元的数据拆分到多个数据库中
* 网络通信协议（诸如TCP/UDP等等）、网络IO（Blocking-IO，NonBlocking-IO、Asyn-IO）、网卡（多队列等）
* 分布式事务就是为了保证不同数据库的数据一致性（数据库分库分表、应用SOA化）
* 事务的ACID（原子性（A）、一致性（C）、隔离性（I）、持久性（D））
* 基于XA协议的两阶段提交（事务管理器和本地资源管理器，本地资源管理器往往由数据库实现，比如Oracle、DB2这些商业数据库都实现了XA接口，而事务管理器作为全局的调度者，负责各个本地资源的提交和回滚；XA无法满足高并发场景。XA目前在商业数据库支持的比较理想，在mysql数据库中支持的不太理想，mysql的XA实现，没有记录prepare阶段日志）

# java8
* 接口的默认方法
* Lambda 表达式
* 函数式接口
* 方法与构造函数引用
* Lambda 作用域
* 访问局部变量
* 访问对象字段与静态变量
* 访问接口的默认方法
* Date API
* Annotation 注解（在Java 8中支持多重注解了，Java 8允许我们把同一个类型的注解使用多次，只需要给该注解标注一下@Repeatable即可）

# 前后端分离
* 展示前台可以用nodejs，后台部分可以用java，前后台分离，使java开发人员可以更加关注后台的开发（前端：负责View和Controller层、后端：只负责Model层，业务处理/数据）
* 后端MVC的模式进行开发，这种模式严重阻碍了前端开发效率，也让后端不能专注于业务开发；；让前端能控制Controller层；；Node应用中有一层Model Proxy与服务端进行通讯。这一层主要目前是抹平我们对不同接口的调用方式，封装一些view层需要的Model
* Node层要使用什么框架由开发者自己决定。不过推荐使用express+xTemplate的组合，xTemplate能做到前后端公用
* 可以使用Node轻松实现我们想要的输出方式:JSON/JSONP/RESTful/HTML/BigPipe/Comet/Socket/同步、异步，想怎么整就怎么整，完全根据你的场景决定
* NodeJS：合并请求，统一返回，降低负担，分批输出
拆分大接口为独立小接口，缩短请求时间
一台Node服务器，对多台Java服务器，合理分配服务器
